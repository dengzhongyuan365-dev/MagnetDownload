# ğŸš€ é˜¶æ®µ1å®ç°æŒ‡å—ï¼šæ ¸å¿ƒåŸºç¡€è®¾æ–½

åŸºäºä½ çš„Asioå®éªŒç»éªŒï¼Œç°åœ¨å¼€å§‹æ„å»ºç£åŠ›ä¸‹è½½å™¨çš„æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼

## ğŸ“‹ é˜¶æ®µ1æ¦‚è§ˆ

### ğŸ¯ **æ ¸å¿ƒç›®æ ‡**
å»ºç«‹æ•´ä¸ªç³»ç»Ÿçš„"è„Šæ¢éª¨" - å¤šçº¿ç¨‹äº‹ä»¶å¾ªç¯å’Œä»»åŠ¡è°ƒåº¦ç³»ç»Ÿï¼Œä¸ºåç»­æ‰€æœ‰æ¨¡å—æä¾›é«˜æ•ˆã€ç¨³å®šçš„è¿è¡ŒåŸºç¡€ã€‚

### ğŸ“¦ **å®ç°æ¨¡å—ä¼˜å…ˆçº§**
1. âœ… **Logger** (æœ€ç®€å•ï¼Œå…¶ä»–æ¨¡å—éƒ½éœ€è¦)
2. âœ… **Config** (é…ç½®æ”¯æŒ)
3. âœ… **EventLoopManager** (æ ¸å¿ƒäº‹ä»¶å¾ªç¯)
4. âœ… **TaskScheduler** (ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ)

---

## ğŸ”§ æ¨¡å—1ï¼šLogger - å¤šçº§æ—¥å¿—ç³»ç»Ÿ

### ğŸ¯ **è®¾è®¡ç›®æ ‡**
- çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—è¾“å‡º
- æ”¯æŒå¤šä¸ªæ—¥å¿—çº§åˆ«
- å¯é…ç½®çš„è¾“å‡ºæ ¼å¼
- é«˜æ€§èƒ½å¼‚æ­¥æ—¥å¿—

### ğŸ—ï¸ **æ ¸å¿ƒè®¾è®¡æ€è·¯**

åŸºäºä½ åœ¨å®éªŒ6ä¸­æŒæ¡çš„å¤šçº¿ç¨‹çŸ¥è¯†ï¼š

```cpp
// include/core/logger.h
#pragma once
#include <iostream>
#include <fstream>
#include <sstream>
#include <memory>
#include <mutex>
#include <atomic>
#include <thread>
#include <queue>
#include <condition_variable>
#include <chrono>

namespace magnet {

enum class LogLevel {
    DEBUG = 0,
    INFO = 1,
    WARN = 2,
    ERROR = 3,
    FATAL = 4
};

struct LogEntry {
    LogLevel level;
    std::string message;
    std::chrono::system_clock::time_point timestamp;
    std::thread::id thread_id;
    
    LogEntry(LogLevel lvl, std::string msg) 
        : level(lvl), message(std::move(msg))
        , timestamp(std::chrono::system_clock::now())
        , thread_id(std::this_thread::get_id()) {}
};

class Logger {
public:
    static Logger& instance();
    
    void set_level(LogLevel level);
    void set_output_file(const std::string& filename);
    
    void log(LogLevel level, const std::string& message);
    
    // ä¾¿æ·å®å®šä¹‰åä¼šç”¨åˆ°çš„æ¥å£
    void debug(const std::string& message) { log(LogLevel::DEBUG, message); }
    void info(const std::string& message) { log(LogLevel::INFO, message); }
    void warn(const std::string& message) { log(LogLevel::WARN, message); }
    void error(const std::string& message) { log(LogLevel::ERROR, message); }
    void fatal(const std::string& message) { log(LogLevel::FATAL, message); }
    
    ~Logger();

private:
    Logger();
    
    // å¼‚æ­¥æ—¥å¿—å¤„ç†
    void worker_thread();
    std::string format_entry(const LogEntry& entry) const;
    std::string level_to_string(LogLevel level) const;
    
    std::atomic<LogLevel> min_level_{LogLevel::INFO};
    std::queue<LogEntry> log_queue_;
    std::mutex queue_mutex_;
    std::condition_variable queue_cv_;
    std::atomic<bool> stop_flag_{false};
    std::thread worker_thread_;
    
    std::unique_ptr<std::ofstream> file_output_;
    std::mutex output_mutex_;
};

// ä¾¿æ·å®å®šä¹‰
#define LOG_DEBUG(msg) Logger::instance().debug(msg)
#define LOG_INFO(msg) Logger::instance().info(msg)
#define LOG_WARN(msg) Logger::instance().warn(msg)
#define LOG_ERROR(msg) Logger::instance().error(msg)
#define LOG_FATAL(msg) Logger::instance().fatal(msg)

// æ ¼å¼åŒ–æ—¥å¿—å®
#define LOG_INFO_F(fmt, ...) do { \
    char buffer[1024]; \
    snprintf(buffer, sizeof(buffer), fmt, __VA_ARGS__); \
    Logger::instance().info(buffer); \
} while(0)

} // namespace magnet
```

### ğŸ’¡ **å®ç°è¦ç‚¹**

#### **å¼‚æ­¥æ—¥å¿—é˜Ÿåˆ—**
åŸºäºä½ åœ¨å®éªŒ6å­¦åˆ°çš„çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—æ€æƒ³ï¼š
- ä¸»çº¿ç¨‹å¿«é€ŸæŠ•é€’æ—¥å¿—åˆ°é˜Ÿåˆ—
- ä¸“é—¨çš„å·¥ä½œçº¿ç¨‹è´Ÿè´£æ ¼å¼åŒ–å’Œå†™å…¥
- é¿å…IOæ“ä½œé˜»å¡ä¸šåŠ¡çº¿ç¨‹

#### **å•ä¾‹æ¨¡å¼çš„çº¿ç¨‹å®‰å…¨å®ç°**
```cpp
Logger& Logger::instance() {
    static Logger instance;  // C++11ä¿è¯çº¿ç¨‹å®‰å…¨çš„åˆå§‹åŒ–
    return instance;
}
```

#### **æ¡ä»¶å˜é‡çš„æ­£ç¡®ä½¿ç”¨**
```cpp
void Logger::log(LogLevel level, const std::string& message) {
    if (level < min_level_.load()) {
        return;  // æ—©æœŸè¿‡æ»¤ï¼Œé¿å…ä¸å¿…è¦çš„å­—ç¬¦ä¸²æ“ä½œ
    }
    
    {
        std::lock_guard<std::mutex> lock(queue_mutex_);
        log_queue_.emplace(level, message);
    }
    queue_cv_.notify_one();  // é€šçŸ¥å·¥ä½œçº¿ç¨‹
}
```

### ğŸ§ª **æµ‹è¯•ç”¨ä¾‹è®¾è®¡**
```cpp
// tests/test_logger.cpp
void test_logger_basic() {
    Logger& logger = Logger::instance();
    logger.set_level(LogLevel::DEBUG);
    
    LOG_INFO("Loggeræµ‹è¯•å¼€å§‹");
    LOG_DEBUG("è¿™æ˜¯è°ƒè¯•ä¿¡æ¯");
    LOG_ERROR("è¿™æ˜¯é”™è¯¯ä¿¡æ¯");
    
    // ç­‰å¾…å¼‚æ­¥æ—¥å¿—å†™å…¥å®Œæˆ
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
}

void test_logger_multithread() {
    const int thread_count = 10;
    const int messages_per_thread = 100;
    
    std::vector<std::thread> threads;
    
    for (int i = 0; i < thread_count; ++i) {
        threads.emplace_back([i, messages_per_thread]() {
            for (int j = 0; j < messages_per_thread; ++j) {
                LOG_INFO_F("çº¿ç¨‹%dæ¶ˆæ¯%d", i, j);
            }
        });
    }
    
    for (auto& t : threads) {
        t.join();
    }
    
    LOG_INFO("å¤šçº¿ç¨‹æ—¥å¿—æµ‹è¯•å®Œæˆ");
}
```

---

## ğŸ”§ æ¨¡å—2ï¼šConfig - é…ç½®ç®¡ç†ç³»ç»Ÿ

### ğŸ¯ **è®¾è®¡ç›®æ ‡**
- æ”¯æŒä»æ–‡ä»¶å’Œå‘½ä»¤è¡Œè¯»å–é…ç½®
- ç±»å‹å®‰å…¨çš„é…ç½®è®¿é—®
- é…ç½®çƒ­é‡è½½æ”¯æŒ
- é»˜è®¤å€¼ç®¡ç†

### ğŸ—ï¸ **æ ¸å¿ƒè®¾è®¡æ€è·¯**

```cpp
// include/core/config.h
#pragma once
#include <unordered_map>
#include <string>
#include <variant>
#include <optional>
#include <mutex>

namespace magnet {

// æ”¯æŒçš„é…ç½®å€¼ç±»å‹
using ConfigValue = std::variant<std::string, int, double, bool>;

class Config {
public:
    static Config& instance();
    
    // ä»æ–‡ä»¶åŠ è½½é…ç½®
    bool load_from_file(const std::string& filename);
    
    // å‘½ä»¤è¡Œå‚æ•°è§£æ
    bool parse_command_line(int argc, char* argv[]);
    
    // è·å–é…ç½®å€¼ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
    template<typename T>
    T get(const std::string& key, const T& default_value) const;
    
    // è®¾ç½®é…ç½®å€¼
    template<typename T>
    void set(const std::string& key, const T& value);
    
    // æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨
    bool has(const std::string& key) const;
    
    // è·å–æ‰€æœ‰é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    std::unordered_map<std::string, ConfigValue> get_all() const;

private:
    Config() = default;
    
    mutable std::shared_mutex config_mutex_;  // è¯»å†™é”
    std::unordered_map<std::string, ConfigValue> config_data_;
    
    // å­—ç¬¦ä¸²åˆ°å…¶ä»–ç±»å‹çš„è½¬æ¢
    template<typename T>
    std::optional<T> string_to_value(const std::string& str) const;
};

// ä¾¿æ·å®
#define GET_CONFIG(key, default_val) Config::instance().get(key, default_val)
#define SET_CONFIG(key, val) Config::instance().set(key, val)

} // namespace magnet
```

### ğŸ’¡ **å®ç°è¦ç‚¹**

#### **ç±»å‹å®‰å…¨çš„é…ç½®è®¿é—®**
åŸºäºä½ å­¦è¿‡çš„`std::variant`ï¼š
```cpp
template<typename T>
T Config::get(const std::string& key, const T& default_value) const {
    std::shared_lock<std::shared_mutex> lock(config_mutex_);
    
    auto it = config_data_.find(key);
    if (it == config_data_.end()) {
        return default_value;
    }
    
    try {
        return std::get<T>(it->second);
    } catch (const std::bad_variant_access&) {
        LOG_WARN_F("é…ç½®é¡¹ %s ç±»å‹ä¸åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤å€¼", key.c_str());
        return default_value;
    }
}
```

#### **é…ç½®æ–‡ä»¶æ ¼å¼è®¾è®¡**
ç®€å•çš„key=valueæ ¼å¼ï¼š
```ini
# MagnetDownloaderé…ç½®æ–‡ä»¶
log_level=INFO
max_connections=50
download_dir=./downloads
listen_port=6881
dht_bootstrap_nodes=router.bittorrent.com:6881,dht.transmissionbt.com:6881
```

### ğŸ§ª **æµ‹è¯•ç”¨ä¾‹è®¾è®¡**
```cpp
void test_config_basic() {
    Config& config = Config::instance();
    
    // æµ‹è¯•åŸºæœ¬çš„set/get
    config.set("test_string", std::string("hello"));
    config.set("test_int", 42);
    config.set("test_bool", true);
    
    assert(config.get<std::string>("test_string", "") == "hello");
    assert(config.get<int>("test_int", 0) == 42);
    assert(config.get<bool>("test_bool", false) == true);
    
    LOG_INFO("é…ç½®ç³»ç»ŸåŸºç¡€æµ‹è¯•é€šè¿‡");
}
```

---

## ğŸ”§ æ¨¡å—3ï¼šEventLoopManager - äº‹ä»¶å¾ªç¯ç®¡ç†å™¨

### ğŸ¯ **è®¾è®¡ç›®æ ‡**
- ç®¡ç†å¤šä¸ªå·¥ä½œçº¿ç¨‹çš„io_context
- è´Ÿè½½å‡è¡¡çš„ä»»åŠ¡åˆ†é…
- ä¼˜é›…çš„å¯åŠ¨å’Œåœæ­¢
- çº¿ç¨‹æ± åŠ¨æ€è°ƒæ•´
- **æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§å¤„ç†**ï¼ˆä¸TaskSchedulerååŒå·¥ä½œï¼‰

### ğŸ¤” **è®¾è®¡å†³ç­–ï¼šäº‹ä»¶å¾ªç¯æ˜¯å¦éœ€è¦ä¼˜å…ˆçº§ï¼Ÿ**

è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„æ¶æ„å†³ç­–ã€‚æˆ‘ä»¬æœ‰ä¸¤ç§æ–¹æ¡ˆï¼š

#### **æ–¹æ¡ˆAï¼šç®€å•åˆ†å±‚ï¼ˆæ¨èå­¦ä¹ é˜¶æ®µï¼‰**
- **EventLoopManager**: è´Ÿè´£è´Ÿè½½å‡è¡¡ï¼Œæ‰€æœ‰io_contextå¹³ç­‰å¤„ç†ä»»åŠ¡
- **TaskScheduler**: è´Ÿè´£ä¼˜å…ˆçº§æ’åºï¼Œç„¶åå°†ä»»åŠ¡æäº¤ç»™EventLoopManager

**ä¼˜ç‚¹**ï¼š
- èŒè´£æ¸…æ™°ï¼Œæ¨¡å—é—´è§£è€¦
- EventLoopManagerå®ç°ç®€å•
- æ˜“äºç†è§£å’Œè°ƒè¯•

**ç¼ºç‚¹**ï¼š
- æ‰€æœ‰ä»»åŠ¡éƒ½è¦ç»è¿‡TaskSchedulerï¼Œå¢åŠ ä¸€å±‚é—´æ¥æ€§
- å¯¹äºç´§æ€¥ç½‘ç»œäº‹ä»¶ï¼ˆå¦‚è¿æ¥æ–­å¼€ï¼‰å“åº”å¯èƒ½ä¸å¤Ÿå¿«

#### **æ–¹æ¡ˆBï¼šæ··åˆä¼˜å…ˆçº§ï¼ˆäº§å“é˜¶æ®µï¼‰**
- **EventLoopManager**: æä¾›å¤šä¸ªä¼˜å…ˆçº§é˜Ÿåˆ—å’Œä¸“ç”¨çº¿ç¨‹æ± 
- **TaskScheduler**: æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„äº‹ä»¶å¾ªç¯

**ä¼˜ç‚¹**ï¼š
- ç½‘ç»œäº‹ä»¶å¯ç›´æ¥è¿›å…¥é«˜ä¼˜å…ˆçº§äº‹ä»¶å¾ªç¯
- æ›´å¥½çš„å®æ—¶å“åº”æ€§èƒ½
- ç³»ç»Ÿååé‡æ›´é«˜

**ç¼ºç‚¹**ï¼š
- å®ç°å¤æ‚åº¦å¤§å¹…å¢åŠ 
- çº¿ç¨‹é—´è´Ÿè½½ä¸å‡è¡¡çš„é£é™©
- è°ƒè¯•éš¾åº¦æå‡

#### **æˆ‘ä»¬çš„æ¸è¿›ç­–ç•¥**

åŸºäºä½ çš„å­¦ä¹ ç›®æ ‡ï¼Œå»ºè®®ï¼š

1. **é˜¶æ®µ1**: é‡‡ç”¨æ–¹æ¡ˆAï¼Œä¸“æ³¨ç†è§£åŸºç¡€æ¦‚å¿µ
2. **é˜¶æ®µ4-6**: æ ¹æ®å®é™…æ€§èƒ½éœ€æ±‚ï¼Œè€ƒè™‘å‡çº§åˆ°æ–¹æ¡ˆB

è¿™æ ·ä½ æ—¢èƒ½æŒæ¡æ¸…æ™°çš„æ¶æ„æ€ç»´ï¼Œåˆä¸ä¼šä¸€å¼€å§‹å°±é™·å…¥è¿‡åº¦å¤æ‚çš„è®¾è®¡ä¸­ã€‚

### ğŸ—ï¸ **æ ¸å¿ƒè®¾è®¡æ€è·¯**

ç›´æ¥åº”ç”¨ä½ åœ¨å®éªŒ6ä¸­å­¦åˆ°çš„å¤šçº¿ç¨‹io_contextæ¨¡å¼ï¼š

```cpp
// include/core/event_loop_manager.h
#pragma once
#include <asio.hpp>
#include <vector>
#include <thread>
#include <atomic>
#include <memory>
#include <functional>

namespace magnet {

class EventLoopManager {
public:
    explicit EventLoopManager(size_t thread_count = std::thread::hardware_concurrency());
    ~EventLoopManager();
    
    // å¯åŠ¨æ‰€æœ‰å·¥ä½œçº¿ç¨‹
    void start();
    
    // åœæ­¢æ‰€æœ‰å·¥ä½œçº¿ç¨‹
    void stop();
    
    // è·å–è´Ÿè½½æœ€è½»çš„io_context
    asio::io_context& get_io_context();
    
    // æŠ•é€’ä»»åŠ¡åˆ°æŒ‡å®šçš„io_context
    template<typename Handler>
    void post(Handler&& handler);
    
    // æŠ•é€’ä»»åŠ¡åˆ°è´Ÿè½½æœ€è½»çš„io_context
    template<typename Handler>
    void post_to_least_loaded(Handler&& handler);
    
    // è·å–ç»Ÿè®¡ä¿¡æ¯
    struct Statistics {
        size_t thread_count;
        std::vector<size_t> tasks_per_thread;
        size_t total_tasks_handled;
    };
    Statistics get_statistics() const;
    
    bool is_running() const { return running_.load(); }

private:
    struct ThreadContext {
        std::unique_ptr<asio::io_context> io_context;
        std::unique_ptr<asio::executor_work_guard<asio::io_context::executor_type>> work_guard;
        std::unique_ptr<std::thread> thread;
        std::atomic<size_t> task_count{0};  // è´Ÿè½½å‡è¡¡ç”¨
        
        ThreadContext() 
            : io_context(std::make_unique<asio::io_context>())
            , work_guard(std::make_unique<asio::executor_work_guard<asio::io_context::executor_type>>(
                asio::make_work_guard(*io_context))) {}
    };
    
    std::vector<ThreadContext> thread_contexts_;
    std::atomic<bool> running_{false};
    std::atomic<size_t> next_context_index_{0};  // è½®è¯¢åˆ†é…
    
    void worker_thread_func(size_t index);
    size_t select_least_loaded_context() const;
};

template<typename Handler>
void EventLoopManager::post(Handler&& handler) {
    if (!running_.load()) {
        LOG_WARN("EventLoopManageræœªè¿è¡Œï¼Œä»»åŠ¡è¢«ä¸¢å¼ƒ");
        return;
    }
    
    auto& context = get_io_context();
    asio::post(context, std::forward<Handler>(handler));
}

template<typename Handler>
void EventLoopManager::post_to_least_loaded(Handler&& handler) {
    if (!running_.load()) {
        LOG_WARN("EventLoopManageræœªè¿è¡Œï¼Œä»»åŠ¡è¢«ä¸¢å¼ƒ");
        return;
    }
    
    size_t index = select_least_loaded_context();
    auto& context = thread_contexts_[index];
    context.task_count.fetch_add(1);
    
    asio::post(*context.io_context, [handler = std::forward<Handler>(handler), &context]() {
        handler();
        context.task_count.fetch_sub(1);
    });
}

} // namespace magnet
```

### ğŸ’¡ **å®ç°è¦ç‚¹**

#### **æ™ºèƒ½è´Ÿè½½å‡è¡¡**
åŸºäºå®é™…ä»»åŠ¡è®¡æ•°è€Œä¸æ˜¯ç®€å•è½®è¯¢ï¼š
```cpp
size_t EventLoopManager::select_least_loaded_context() const {
    size_t min_tasks = SIZE_MAX;
    size_t best_index = 0;
    
    for (size_t i = 0; i < thread_contexts_.size(); ++i) {
        size_t task_count = thread_contexts_[i].task_count.load();
        if (task_count < min_tasks) {
            min_tasks = task_count;
            best_index = i;
        }
    }
    
    return best_index;
}
```

#### **ä¼˜é›…åœæ­¢æœºåˆ¶**
åŸºäºä½ æŒæ¡çš„work_guardæœºåˆ¶ï¼š
```cpp
void EventLoopManager::stop() {
    if (!running_.exchange(false)) {
        return;  // å·²ç»åœæ­¢
    }
    
    LOG_INFO("æ­£åœ¨åœæ­¢EventLoopManager...");
    
    // 1. é‡Šæ”¾æ‰€æœ‰work_guardï¼Œå…è®¸io_context.run()é€€å‡º
    for (auto& context : thread_contexts_) {
        context.work_guard.reset();
    }
    
    // 2. ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for (auto& context : thread_contexts_) {
        if (context.thread && context.thread->joinable()) {
            context.thread->join();
        }
    }
    
    LOG_INFO("EventLoopManagerå·²åœæ­¢");
}
```

### ğŸ§ª **æµ‹è¯•ç”¨ä¾‹è®¾è®¡**
```cpp
void test_event_loop_manager() {
    EventLoopManager manager(4);
    manager.start();
    
    std::atomic<int> completed_tasks{0};
    const int total_tasks = 100;
    
    // æŠ•é€’100ä¸ªä»»åŠ¡
    for (int i = 0; i < total_tasks; ++i) {
        manager.post([&completed_tasks, i]() {
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            completed_tasks.fetch_add(1);
            if (i % 10 == 0) {
                LOG_INFO_F("å®Œæˆä»»åŠ¡ %d", i);
            }
        });
    }
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    while (completed_tasks.load() < total_tasks) {
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
    
    auto stats = manager.get_statistics();
    LOG_INFO_F("ç»Ÿè®¡ï¼š%zuä¸ªçº¿ç¨‹ï¼Œæ€»è®¡å¤„ç†%zuä¸ªä»»åŠ¡", stats.thread_count, stats.total_tasks_handled);
    
    manager.stop();
}
```

---

## ğŸ”§ æ¨¡å—4ï¼šTaskScheduler - ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ

### ğŸ¯ **è®¾è®¡ç›®æ ‡**
- æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§
- å»¶è¿Ÿä»»åŠ¡æ‰§è¡Œ
- å‘¨æœŸæ€§ä»»åŠ¡
- ä»»åŠ¡å–æ¶ˆæœºåˆ¶
- **ä¸EventLoopManagerååŒå·¥ä½œ**

### ğŸ¤ **æ¨¡å—åä½œå…³ç³»**

åœ¨æˆ‘ä»¬çš„åˆ†å±‚è®¾è®¡ä¸­ï¼š

```
åº”ç”¨å±‚ä»»åŠ¡
    â†“
TaskSchedulerï¼ˆä¼˜å…ˆçº§æ’åºã€å»¶è¿Ÿè°ƒåº¦ï¼‰
    â†“
EventLoopManagerï¼ˆè´Ÿè½½å‡è¡¡åˆ†å‘ï¼‰
    â†“
å¤šä¸ªio_contextå·¥ä½œçº¿ç¨‹ï¼ˆå®é™…æ‰§è¡Œï¼‰
```

**æ ¸å¿ƒåä½œåŸç†**ï¼š
- TaskSchedulerç»´æŠ¤ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œç¡®ä¿é‡è¦ä»»åŠ¡å…ˆæ‰§è¡Œ
- TaskSchedulerä½¿ç”¨å®šæ—¶å™¨å¤„ç†å»¶è¿Ÿä»»åŠ¡å’Œå‘¨æœŸæ€§ä»»åŠ¡
- å½“ä»»åŠ¡å°±ç»ªæ—¶ï¼ŒTaskSchedulerè°ƒç”¨EventLoopManagerçš„è´Ÿè½½å‡è¡¡æ¥å£
- EventLoopManageré€‰æ‹©æœ€åˆé€‚çš„å·¥ä½œçº¿ç¨‹æ‰§è¡Œå…·ä½“ä»»åŠ¡

è¿™ç§è®¾è®¡è®©æ¯ä¸ªæ¨¡å—ä¸“æ³¨è‡ªå·±çš„æ ¸å¿ƒèŒè´£ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆåä½œã€‚

### ğŸ—ï¸ **æ ¸å¿ƒè®¾è®¡æ€è·¯**

```cpp
// include/core/task_scheduler.h
#pragma once
#include "event_loop_manager.h"
#include <functional>
#include <chrono>
#include <queue>
#include <memory>
#include <atomic>

namespace magnet {

enum class TaskPriority {
    LOW = 0,
    NORMAL = 1,
    HIGH = 2,
    CRITICAL = 3
};

class Task {
public:
    using TaskFunction = std::function<void()>;
    using TaskId = uint64_t;
    
    Task(TaskFunction func, TaskPriority priority = TaskPriority::NORMAL)
        : function_(std::move(func)), priority_(priority), id_(generate_id()) {}
    
    void execute() const { if (function_) function_(); }
    TaskPriority priority() const { return priority_; }
    TaskId id() const { return id_; }
    
private:
    TaskFunction function_;
    TaskPriority priority_;
    TaskId id_;
    
    static TaskId generate_id();
};

class TaskScheduler {
public:
    explicit TaskScheduler(EventLoopManager& loop_manager);
    ~TaskScheduler();
    
    // ç«‹å³æ‰§è¡Œä»»åŠ¡
    Task::TaskId post_task(TaskPriority priority, Task::TaskFunction func);
    
    // å»¶è¿Ÿæ‰§è¡Œä»»åŠ¡
    Task::TaskId post_delayed_task(
        std::chrono::milliseconds delay,
        TaskPriority priority,
        Task::TaskFunction func
    );
    
    // å‘¨æœŸæ€§ä»»åŠ¡
    Task::TaskId post_periodic_task(
        std::chrono::milliseconds interval,
        TaskPriority priority,
        Task::TaskFunction func
    );
    
    // å–æ¶ˆä»»åŠ¡
    bool cancel_task(Task::TaskId task_id);
    
    // è·å–ç»Ÿè®¡ä¿¡æ¯
    struct Statistics {
        size_t pending_tasks;
        size_t completed_tasks;
        std::array<size_t, 4> tasks_by_priority;  // æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
    };
    Statistics get_statistics() const;

private:
    EventLoopManager& loop_manager_;
    
    // ä¼˜å…ˆçº§é˜Ÿåˆ—æ¯”è¾ƒå™¨
    struct TaskComparator {
        bool operator()(const std::shared_ptr<Task>& a, const std::shared_ptr<Task>& b) const {
            return a->priority() < b->priority();  // é«˜ä¼˜å…ˆçº§å…ˆæ‰§è¡Œ
        }
    };
    
    std::priority_queue<
        std::shared_ptr<Task>,
        std::vector<std::shared_ptr<Task>>,
        TaskComparator
    > task_queue_;
    
    std::mutex queue_mutex_;
    std::condition_variable queue_cv_;
    std::atomic<bool> running_{true};
    std::thread scheduler_thread_;
    
    // å–æ¶ˆæœºåˆ¶
    std::unordered_set<Task::TaskId> cancelled_tasks_;
    std::mutex cancelled_mutex_;
    
    // ç»Ÿè®¡ä¿¡æ¯
    mutable std::mutex stats_mutex_;
    Statistics statistics_;
    
    void scheduler_thread_func();
    bool is_task_cancelled(Task::TaskId task_id) const;
};

} // namespace magnet
```

### ğŸ’¡ **å®ç°è¦ç‚¹**

#### **ä¼˜å…ˆçº§é˜Ÿåˆ—çš„ä½¿ç”¨**
åŸºäºC++æ ‡å‡†åº“çš„priority_queueï¼š
```cpp
void TaskScheduler::scheduler_thread_func() {
    while (running_.load()) {
        std::shared_ptr<Task> task;
        
        {
            std::unique_lock<std::mutex> lock(queue_mutex_);
            queue_cv_.wait(lock, [this]() {
                return !task_queue_.empty() || !running_.load();
            });
            
            if (!running_.load()) break;
            
            task = task_queue_.top();
            task_queue_.pop();
        }
        
        // æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ
        if (!is_task_cancelled(task->id())) {
            // æäº¤åˆ°EventLoopManageræ‰§è¡Œ
            loop_manager_.post_to_least_loaded([task]() {
                task->execute();
            });
            
            // æ›´æ–°ç»Ÿè®¡
            {
                std::lock_guard<std::mutex> stats_lock(stats_mutex_);
                statistics_.completed_tasks++;
            }
        }
    }
}
```

#### **å»¶è¿Ÿä»»åŠ¡çš„å®ç°**
ä½¿ç”¨asio::steady_timerï¼š
```cpp
Task::TaskId TaskScheduler::post_delayed_task(
    std::chrono::milliseconds delay,
    TaskPriority priority,
    Task::TaskFunction func) {
    
    auto timer = std::make_shared<asio::steady_timer>(
        loop_manager_.get_io_context(), delay);
    
    auto task = std::make_shared<Task>(std::move(func), priority);
    Task::TaskId task_id = task->id();
    
    timer->async_wait([this, task, timer](const asio::error_code& ec) {
        if (!ec && !is_task_cancelled(task->id())) {
            // å°†å»¶è¿Ÿä»»åŠ¡åŠ å…¥ä¼˜å…ˆçº§é˜Ÿåˆ—
            {
                std::lock_guard<std::mutex> lock(queue_mutex_);
                task_queue_.push(task);
            }
            queue_cv_.notify_one();
        }
    });
    
    return task_id;
}
```

### ğŸ§ª **æµ‹è¯•ç”¨ä¾‹è®¾è®¡**
```cpp
void test_task_scheduler() {
    EventLoopManager loop_manager(2);
    loop_manager.start();
    
    TaskScheduler scheduler(loop_manager);
    
    std::atomic<int> execution_order{0};
    
    // æµ‹è¯•ä¼˜å…ˆçº§æ’åº
    auto low_task = scheduler.post_task(TaskPriority::LOW, [&]() {
        int order = execution_order.fetch_add(1);
        LOG_INFO_F("ä½ä¼˜å…ˆçº§ä»»åŠ¡æ‰§è¡Œï¼Œé¡ºåº: %d", order);
    });
    
    auto high_task = scheduler.post_task(TaskPriority::HIGH, [&]() {
        int order = execution_order.fetch_add(1);
        LOG_INFO_F("é«˜ä¼˜å…ˆçº§ä»»åŠ¡æ‰§è¡Œï¼Œé¡ºåº: %d", order);
    });
    
    auto critical_task = scheduler.post_task(TaskPriority::CRITICAL, [&]() {
        int order = execution_order.fetch_add(1);
        LOG_INFO_F("å…³é”®ä¼˜å…ˆçº§ä»»åŠ¡æ‰§è¡Œï¼Œé¡ºåº: %d", order);
    });
    
    // æµ‹è¯•å»¶è¿Ÿä»»åŠ¡
    scheduler.post_delayed_task(std::chrono::milliseconds(100), TaskPriority::NORMAL, []() {
        LOG_INFO("å»¶è¿Ÿä»»åŠ¡æ‰§è¡Œ");
    });
    
    std::this_thread::sleep_for(std::chrono::milliseconds(200));
    
    auto stats = scheduler.get_statistics();
    LOG_INFO_F("è°ƒåº¦å™¨ç»Ÿè®¡ï¼šå®Œæˆ%zuä¸ªä»»åŠ¡", stats.completed_tasks);
    
    loop_manager.stop();
}
```

---

## ğŸª é˜¶æ®µ1é›†æˆæµ‹è¯•

### ğŸ¯ **ç›®æ ‡ï¼šHello MagnetDownloader**
åˆ›å»ºä¸€ä¸ªç»¼åˆæµ‹è¯•ç¨‹åºï¼ŒéªŒè¯æ‰€æœ‰æ¨¡å—ååŒå·¥ä½œï¼š

```cpp
// examples/hello_magnet_downloader.cpp
#include "core/logger.h"
#include "core/config.h"
#include "core/event_loop_manager.h"
#include "core/task_scheduler.h"
#include <iostream>
#include <thread>

using namespace magnet;

int main() {
    try {
        std::cout << "ğŸš€ MagnetDownloader é˜¶æ®µ1æ¼”ç¤ºç¨‹åº" << std::endl;
        std::cout << "================================================" << std::endl;
        
        // 1. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        Logger::instance().set_level(LogLevel::DEBUG);
        LOG_INFO("ğŸ”§ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ");
        
        // 2. åŠ è½½é…ç½®
        Config::instance().set("worker_threads", 4);
        Config::instance().set("max_tasks", 100);
        LOG_INFO("âš™ï¸ é…ç½®ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ");
        
        // 3. å¯åŠ¨äº‹ä»¶å¾ªç¯ç®¡ç†å™¨
        int thread_count = GET_CONFIG("worker_threads", 4);
        EventLoopManager loop_manager(thread_count);
        loop_manager.start();
        LOG_INFO_F("ğŸ”„ äº‹ä»¶å¾ªç¯ç®¡ç†å™¨å¯åŠ¨ï¼Œ%dä¸ªå·¥ä½œçº¿ç¨‹", thread_count);
        
        // 4. å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨
        TaskScheduler scheduler(loop_manager);
        LOG_INFO("ğŸ“‹ ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨å®Œæˆ");
        
        // 5. æ¼”ç¤ºå¤šç§ä»»åŠ¡
        std::atomic<int> demo_counter{0};
        
        // é«˜ä¼˜å…ˆçº§ä»»åŠ¡
        for (int i = 0; i < 5; ++i) {
            scheduler.post_task(TaskPriority::HIGH, [&demo_counter, i]() {
                demo_counter.fetch_add(1);
                LOG_INFO_F("ğŸ”¥ é«˜ä¼˜å…ˆçº§ä»»åŠ¡ %d æ‰§è¡Œ", i);
                std::this_thread::sleep_for(std::chrono::milliseconds(50));
            });
        }
        
        // æ™®é€šä»»åŠ¡
        for (int i = 0; i < 10; ++i) {
            scheduler.post_task(TaskPriority::NORMAL, [&demo_counter, i]() {
                demo_counter.fetch_add(1);
                LOG_INFO_F("âš¡ æ™®é€šä»»åŠ¡ %d æ‰§è¡Œ", i);
                std::this_thread::sleep_for(std::chrono::milliseconds(30));
            });
        }
        
        // å»¶è¿Ÿä»»åŠ¡
        scheduler.post_delayed_task(
            std::chrono::milliseconds(1000),
            TaskPriority::CRITICAL,
            [&demo_counter]() {
                demo_counter.fetch_add(1);
                LOG_INFO("â° å»¶è¿Ÿä»»åŠ¡æ‰§è¡Œ");
            }
        );
        
        // å‘¨æœŸæ€§ä»»åŠ¡ï¼ˆæ‰§è¡Œ3æ¬¡ï¼‰
        std::shared_ptr<std::atomic<int>> periodic_count = std::make_shared<std::atomic<int>>(0);
        std::function<void()> periodic_task = [&scheduler, periodic_count, &demo_counter]() {
            int count = periodic_count->fetch_add(1);
            demo_counter.fetch_add(1);
            LOG_INFO_F("ğŸ”„ å‘¨æœŸæ€§ä»»åŠ¡æ‰§è¡Œ %d æ¬¡", count + 1);
            
            if (count < 2) {  // æ‰§è¡Œ3æ¬¡
                scheduler.post_delayed_task(
                    std::chrono::milliseconds(500),
                    TaskPriority::LOW,
                    periodic_task
                );
            }
        };
        scheduler.post_task(TaskPriority::LOW, periodic_task);
        
        // ğŸ¯ å±•ç¤ºä¼˜å…ˆçº§æ•ˆæœçš„ç‰¹æ®Šæµ‹è¯•
        LOG_INFO("ğŸ­ å¼€å§‹ä¼˜å…ˆçº§æ•ˆæœæ¼”ç¤º...");
        std::this_thread::sleep_for(std::chrono::milliseconds(200));
        
        // åŒæ—¶æäº¤ä¸åŒä¼˜å…ˆçº§ä»»åŠ¡ï¼Œè§‚å¯Ÿæ‰§è¡Œé¡ºåº
        for (int i = 0; i < 3; ++i) {
            scheduler.post_task(TaskPriority::LOW, [i]() {
                LOG_INFO_F("ğŸŒ ä½ä¼˜å…ˆçº§ä»»åŠ¡ %d å¼€å§‹æ‰§è¡Œ", i);
                std::this_thread::sleep_for(std::chrono::milliseconds(100));
                LOG_INFO_F("ğŸŒ ä½ä¼˜å…ˆçº§ä»»åŠ¡ %d å®Œæˆ", i);
            });
        }
        
        // ç¨åæäº¤é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼Œåº”è¯¥æ’é˜Ÿæ‰§è¡Œ
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        scheduler.post_task(TaskPriority::CRITICAL, []() {
            LOG_INFO("ğŸš¨ ç´§æ€¥ä»»åŠ¡æ’é˜Ÿæ‰§è¡Œï¼");
        });
        
        std::this_thread::sleep_for(std::chrono::milliseconds(300));
        
        // 6. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        LOG_INFO("â³ ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...");
        const int expected_tasks = 5 + 10 + 1 + 3 + 3 + 1;  // 23ä¸ªä»»åŠ¡ï¼ˆæ–°å¢ä¼˜å…ˆçº§æ¼”ç¤ºä»»åŠ¡ï¼‰
        
        while (demo_counter.load() < expected_tasks) {
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
            
            auto loop_stats = loop_manager.get_statistics();
            auto scheduler_stats = scheduler.get_statistics();
            
            if (demo_counter.load() % 5 == 0) {
                LOG_INFO_F("ğŸ“Š è¿›åº¦ï¼š%d/%d ä»»åŠ¡å®Œæˆ", demo_counter.load(), expected_tasks);
            }
        }
        
        // 7. å±•ç¤ºç»Ÿè®¡ä¿¡æ¯
        auto loop_stats = loop_manager.get_statistics();
        auto scheduler_stats = scheduler.get_statistics();
        
        std::cout << "\nğŸ“Š æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯ï¼š" << std::endl;
        std::cout << "====================" << std::endl;
        std::cout << "äº‹ä»¶å¾ªç¯ç®¡ç†å™¨ï¼š" << std::endl;
        std::cout << "  - å·¥ä½œçº¿ç¨‹æ•°: " << loop_stats.thread_count << std::endl;
        std::cout << "  - æ€»å¤„ç†ä»»åŠ¡: " << loop_stats.total_tasks_handled << std::endl;
        
        std::cout << "ä»»åŠ¡è°ƒåº¦å™¨ï¼š" << std::endl;
        std::cout << "  - å®Œæˆä»»åŠ¡æ•°: " << scheduler_stats.completed_tasks << std::endl;
        std::cout << "  - é«˜ä¼˜å…ˆçº§: " << scheduler_stats.tasks_by_priority[3] << std::endl;
        std::cout << "  - æ™®é€šä¼˜å…ˆçº§: " << scheduler_stats.tasks_by_priority[1] << std::endl;
        std::cout << "  - ä½ä¼˜å…ˆçº§: " << scheduler_stats.tasks_by_priority[0] << std::endl;
        
        // 8. ä¼˜é›…åœæ­¢
        LOG_INFO("ğŸ›‘ å¼€å§‹ä¼˜é›…åœæ­¢...");
        loop_manager.stop();
        
        std::cout << "\nâœ… MagnetDownloader é˜¶æ®µ1æ¼”ç¤ºå®Œæˆï¼" << std::endl;
        std::cout << "ğŸ’¡ æ‰€æœ‰æ ¸å¿ƒåŸºç¡€è®¾æ–½æ¨¡å—å·¥ä½œæ­£å¸¸" << std::endl;
        
        return 0;
        
    } catch (const std::exception& e) {
        LOG_FATAL(std::string("ç¨‹åºå¼‚å¸¸é€€å‡º: ") + e.what());
        std::cerr << "âŒ ç¨‹åºå¼‚å¸¸é€€å‡º: " << e.what() << std::endl;
        return 1;
    }
}
```

---

## ğŸ“‹ é˜¶æ®µ1éªŒæ”¶æ ‡å‡†

### âœ… **åŠŸèƒ½éªŒæ”¶**
- [ ] Loggerèƒ½å¤Ÿåœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹æ­£å¸¸è¾“å‡ºæ—¥å¿—
- [ ] Configèƒ½å¤Ÿæ­£ç¡®åŠ è½½å’Œè®¿é—®é…ç½®
- [ ] EventLoopManagerèƒ½å¤Ÿå¯åŠ¨å¤šä¸ªå·¥ä½œçº¿ç¨‹
- [ ] TaskSchedulerèƒ½å¤ŸæŒ‰ä¼˜å…ˆçº§è°ƒåº¦ä»»åŠ¡
- [ ] å»¶è¿Ÿä»»åŠ¡å’Œå‘¨æœŸæ€§ä»»åŠ¡æ­£å¸¸å·¥ä½œ
- [ ] ç¨‹åºèƒ½å¤Ÿä¼˜é›…å¯åŠ¨å’Œåœæ­¢

### âœ… **æ€§èƒ½éªŒæ”¶**
- [ ] 1000ä¸ªä»»åŠ¡èƒ½åœ¨5ç§’å†…å®Œæˆ
- [ ] å†…å­˜ä½¿ç”¨ç¨³å®šï¼Œæ— æ˜æ˜¾æ³„æ¼
- [ ] CPUä½¿ç”¨åˆç†åˆ†å¸ƒåœ¨æ‰€æœ‰å·¥ä½œçº¿ç¨‹

### âœ… **ç¨³å®šæ€§éªŒæ”¶**
- [ ] ç¨‹åºèƒ½è¿ç»­è¿è¡Œ30åˆ†é’Ÿæ— å´©æºƒ
- [ ] æ‰€æœ‰å¼‚å¸¸éƒ½æœ‰æ­£ç¡®çš„é”™è¯¯å¤„ç†
- [ ] å¤šæ¬¡å¯åŠ¨åœæ­¢æ— èµ„æºæ³„æ¼

---

## ğŸ“ é˜¶æ®µ1å­¦ä¹ æˆæœ

å®Œæˆé˜¶æ®µ1åï¼Œä½ å°†æŒæ¡ï¼š

### ğŸ”§ **æŠ€æœ¯æŠ€èƒ½**
- **å¤šçº¿ç¨‹ç¼–ç¨‹**ï¼šäº‹ä»¶å¾ªç¯ã€ä»»åŠ¡é˜Ÿåˆ—ã€çº¿ç¨‹å®‰å…¨
- **ç°ä»£C++ç‰¹æ€§**ï¼šæ™ºèƒ½æŒ‡é’ˆã€åŸå­æ“ä½œã€æ¡ä»¶å˜é‡
- **è®¾è®¡æ¨¡å¼**ï¼šå•ä¾‹ã€RAIIã€è§‚å¯Ÿè€…æ¨¡å¼
- **å¼‚æ­¥ç¼–ç¨‹**ï¼šåŸºäºå›è°ƒçš„å¼‚æ­¥ä»»åŠ¡å¤„ç†

### ğŸ—ï¸ **æ¶æ„èƒ½åŠ›**
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šå¦‚ä½•è®¾è®¡æ¾è€¦åˆçš„ç³»ç»Ÿæ¶æ„
- **æ€§èƒ½ä¼˜åŒ–**ï¼šè´Ÿè½½å‡è¡¡ã€ä¼˜å…ˆçº§è°ƒåº¦
- **å¯æ‰©å±•æ€§**ï¼šå¦‚ä½•è®¾è®¡æ”¯æŒåç»­åŠŸèƒ½æ‰©å±•çš„åŸºç¡€æ¡†æ¶

### ğŸ¯ **ä¸‹ä¸€æ­¥é¢„å‘Š**
é˜¶æ®µ1å®Œæˆåï¼Œä½ å°±æœ‰äº†ä¸€ä¸ªå¼ºå¤§çš„"å¼•æ“"ï¼Œå¯ä»¥æ”¯æ’‘ä»»ä½•å¤æ‚çš„å¼‚æ­¥ç½‘ç»œåº”ç”¨ã€‚

é˜¶æ®µ2æˆ‘ä»¬å°†å®ç°ç£åŠ›é“¾æ¥è§£æï¼Œè®©è¿™ä¸ª"å¼•æ“"å¼€å§‹ç†è§£BitTorrentä¸–ç•Œçš„"è¯­è¨€"ï¼

---

## ğŸ’¡ å®ç°å»ºè®®

### ğŸš€ **å¼€å‘é¡ºåº**
1. **Day 1-2**: å®ç°Loggerï¼Œç«‹å³å¯ç”¨äºè°ƒè¯•
2. **Day 3**: å®ç°Configï¼Œæ”¯æŒåç»­æ¨¡å—é…ç½®
3. **Day 4-6**: å®ç°EventLoopManagerï¼Œæœ€æ ¸å¿ƒçš„æ¨¡å—
4. **Day 7-9**: å®ç°TaskSchedulerï¼Œæ·»åŠ è°ƒåº¦èƒ½åŠ›
5. **Day 10**: é›†æˆæµ‹è¯•å’Œä¼˜åŒ–

### âš ï¸ **å¸¸è§é™·é˜±**
- **è¿‡æ—©ä¼˜åŒ–**ï¼šå…ˆä¿è¯åŠŸèƒ½æ­£ç¡®ï¼Œå†è€ƒè™‘æ€§èƒ½
- **å¼‚å¸¸å®‰å…¨**ï¼šç¡®ä¿æ‰€æœ‰èµ„æºéƒ½æœ‰æ­£ç¡®çš„RAIIç®¡ç†
- **çº¿ç¨‹å®‰å…¨**ï¼šä»”ç»†å®¡æŸ¥æ‰€æœ‰å…±äº«çŠ¶æ€çš„è®¿é—®

### ğŸ” **è°ƒè¯•æŠ€å·§**
- å……åˆ†åˆ©ç”¨ä½ çš„Loggerç³»ç»Ÿ
- ä½¿ç”¨çº¿ç¨‹IDæ¥è¿½è¸ªä»»åŠ¡æ‰§è¡Œ
- æ·»åŠ ç»Ÿè®¡ä¿¡æ¯å¸®åŠ©æ€§èƒ½åˆ†æ

---

## ğŸš€ æœªæ¥æ‰©å±•æ€è€ƒ

### ğŸ“ˆ **æ€§èƒ½ä¼˜åŒ–æ–¹å‘**

å½“ä½ åœ¨åç»­é˜¶æ®µé‡åˆ°æ€§èƒ½ç“¶é¢ˆæ—¶ï¼Œå¯ä»¥è€ƒè™‘è¿™äº›ä¼˜åŒ–ï¼š

1. **EventLoopManagerå‡çº§**ï¼š
   ```cpp
   // æ”¯æŒä¸“ç”¨ç½‘ç»œIOçº¿ç¨‹æ± 
   enum class ThreadPoolType {
       GENERAL,     // é€šç”¨ä»»åŠ¡å¤„ç†
       NETWORK_IO,  // ç½‘ç»œIOä¸“ç”¨
       DISK_IO,     // ç£ç›˜IOä¸“ç”¨
       DHT_CRAWLER  // DHTçˆ¬è™«ä¸“ç”¨
   };
   ```

2. **TaskSchedulerå¢å¼º**ï¼š
   ```cpp
   // ä»»åŠ¡äº²å’Œæ€§ï¼ˆä»»åŠ¡ç»‘å®šåˆ°ç‰¹å®šçº¿ç¨‹ï¼‰
   TaskId post_task_with_affinity(
       TaskPriority priority,
       ThreadPoolType pool_type,
       TaskFunction func
   );
   ```

3. **æ™ºèƒ½è´Ÿè½½å‡è¡¡**ï¼š
   ```cpp
   // åŸºäºä»»åŠ¡ç±»å‹çš„æ™ºèƒ½è·¯ç”±
   class SmartTaskRouter {
       // ç½‘ç»œä»»åŠ¡ â†’ ç½‘ç»œä¸“ç”¨çº¿ç¨‹
       // ç£ç›˜ä»»åŠ¡ â†’ IOä¸“ç”¨çº¿ç¨‹
       // è®¡ç®—ä»»åŠ¡ â†’ é€šç”¨çº¿ç¨‹æ± 
   };
   ```

### ğŸ¯ **æ¶æ„æ¼”è¿›è·¯å¾„**

```
é˜¶æ®µ1: åŸºç¡€è®¾æ–½ â†’ å­¦ä¼šåŸºæœ¬æ¦‚å¿µ
é˜¶æ®µ2-3: ç½‘ç»œåŠŸèƒ½ â†’ å‘ç°æ€§èƒ½çƒ­ç‚¹
é˜¶æ®µ4-5: æ•°æ®å¤„ç† â†’ æ˜ç¡®ä¼˜åŒ–éœ€æ±‚
é˜¶æ®µ6: æ€§èƒ½ä¼˜åŒ– â†’ åº”ç”¨é«˜çº§æŠ€å·§
```

è¿™ç§æ¸è¿›å¼çš„æ¶æ„æ¼”è¿›ï¼Œè®©ä½ æ—¢ä¸ä¼šä¸€å¼€å§‹å°±è¿‡åº¦è®¾è®¡ï¼Œåˆä¿è¯ç³»ç»Ÿå…·å¤‡è‰¯å¥½çš„æ‰©å±•æ€§ï¼

---

## ğŸ‰ å¼€å§‹ä½ çš„å¾ç¨‹

å‡†å¤‡å¥½å¼€å§‹å®ç°äº†å—ï¼Ÿä»Loggerå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ„å»ºä½ çš„ç£åŠ›ä¸‹è½½å™¨åŸºç¡€è®¾æ–½ï¼

è®°ä½ï¼š**ä¼˜ç§€çš„æ¶æ„å¸ˆä¸æ˜¯ä¸€å¼€å§‹å°±è®¾è®¡å‡ºå®Œç¾ç³»ç»Ÿï¼Œè€Œæ˜¯èƒ½å¤Ÿéšç€éœ€æ±‚å˜åŒ–ä¼˜é›…åœ°æ¼”è¿›ç³»ç»Ÿ**ã€‚

è®©æˆ‘ä»¬å¼€å§‹è¿™ä¸ªç²¾å½©çš„å­¦ä¹ ä¹‹æ—…ï¼ ğŸš€
